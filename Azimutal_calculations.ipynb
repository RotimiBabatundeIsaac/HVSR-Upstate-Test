{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804b65cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import hvsrpy\n",
    "from hvsrpy import utils\n",
    "from obspy import read\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from matplotlib import cm\n",
    "# from mpl_toolkits.mplot3d.axes3d import get_test_data\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ffc3b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ce9f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from obspy import read\n",
    "#from obspy import UTCDateTime\n",
    "from obspy.clients.fdsn import Client\n",
    "from obspy import UTCDateTime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#client = Client(\"IRIS\")\n",
    "#net = \"Z9\"  # network of the station\n",
    "#sta = \"E27\"  # station code\n",
    "## sta = \"E18\"  # station code\n",
    "#loc = \"**\"  # to specify the instrument at the station\n",
    "#chan = \"BH*\"\n",
    "\n",
    "#starttime = UTCDateTime(\"2012-09-01T00:00:00\")\n",
    "#endtime = starttime + 60 * 60 * 24  # 24 hours\n",
    "## endtime = starttime + 60 * 60  # 24 hours\n",
    "\n",
    "#st = client.get_waveforms(network=net, station=sta, location=loc, channel=chan, starttime=starttime, endtime=endtime, \n",
    "                        #   attach_response=True\n",
    "                          \n",
    "#print(st)\n",
    "\n",
    "\n",
    "client = Client (\"IRIS\")\n",
    "minlatitude = 26.0\n",
    "maxlatitude = 40.0\n",
    "\n",
    "minlongitude =  -100\n",
    "maxlongitude =  -80\n",
    "\n",
    "net = \"Z9\"\n",
    "sta = \"**\"\n",
    "loc = \"**\"\n",
    "chan = \"BH*\"\n",
    "client = Client(\"IRIS\")\n",
    "starttime = UTCDateTime(\"2010-01-01\")\n",
    "endtime = UTCDateTime(\"2014-12-02\")\n",
    "#startafter= UTCDateTime (\"2024-01-20\")\n",
    "#endafter= UTCDateTime (\"2024-06-30\")\n",
    "\n",
    "\n",
    "clt = client.get_stations(network=\"Z9\", station=\"**\",\n",
    "                                starttime=starttime,minlatitude=minlatitude, maxlatitude=maxlatitude,\n",
    "                                minlongitude=minlongitude, maxlongitude=maxlongitude,\n",
    "                                endtime=endtime) #matchtimeseries = True)\n",
    "\n",
    "print (clt)\n",
    "\n",
    "#st.plot(projection=\"local\",label=False,color_per_network=True) \n",
    "\n",
    "\n",
    "# # Remove instrument response\n",
    "# sr = st[0].stats.sampling_rate\n",
    "# st.remove_response(output='ACC', zero_mean=True, taper=True, taper_fraction=0.05, pre_filt=[0.001, 0.005, sr/3, sr/2], water_level=600)\n",
    "\n",
    "# Save waveform\n",
    "#st.write(\"Apriltoday.mseed\", format=\"MSEED\")\n",
    "\n",
    "#st.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570ebc86-c853-4ff4-846b-0bdf0f75a3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy.clients.fdsn import Client\n",
    "from obspy import UTCDateTime\n",
    "import os\n",
    "\n",
    "Ndays = 1  # Duration of each download period (1 day)\n",
    "total_days = 4  # Total number of successive days to download\n",
    "\n",
    "client = Client(\"IRIS\")\n",
    "net = \"Z9\"\n",
    "sta = \"**\"\n",
    "loc = \"**\"\n",
    "chan = \"BH?\"\n",
    "\n",
    "# Ensure the base output directory exists\n",
    "base_output_dir = \"outputloopdaysnew\"\n",
    "os.makedirs(base_output_dir, exist_ok=True)\n",
    "\n",
    "for network in clt:\n",
    "    for station in network:\n",
    "        # Get station and network codes\n",
    "        sta = station.code\n",
    "        net = network.code\n",
    "        \n",
    "        try:\n",
    "            # Initial start and end times\n",
    "            initial_starttime = UTCDateTime((station.creation_date + 365*24*60*60).strftime('%Y-%m-%d'))\n",
    "        except Exception as e:\n",
    "            print(f\"Error in date conversion for station {station.code}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        for day_offset in range(total_days):\n",
    "            # Calculate start and end time for the current day\n",
    "            starttime = initial_starttime + day_offset * 24 * 60 * 60\n",
    "            endtime = starttime + Ndays * 24 * 60 * 60\n",
    "\n",
    "            # Create a separate folder for each day within the station's directory\n",
    "            station_output_dir = os.path.join(base_output_dir, f\"{net}.{sta}\")\n",
    "            day_output_dir = os.path.join(station_output_dir, starttime.strftime('%Y-%m-%d'))\n",
    "            os.makedirs(day_output_dir, exist_ok=True)\n",
    "\n",
    "            output_file = os.path.join(day_output_dir, f\"{net}.{sta}.{starttime.strftime('%Y-%m-%d')}.mseed\")\n",
    "\n",
    "            # Skip download if file already exists\n",
    "            if os.path.exists(output_file):\n",
    "                print(f\"File {output_file} already exists, skipping download.\")\n",
    "                continue\n",
    "\n",
    "            print(f\"Processing station: {sta}, Day: {day_offset + 1}\")\n",
    "\n",
    "            try:\n",
    "                st = client.get_waveforms(network=net, station=sta, location=loc, channel=chan, starttime=starttime, endtime=endtime)\n",
    "            except Exception as e:\n",
    "                print(f\"Error downloading data for station {sta}: {e}. Trying alternative dates...\")\n",
    "                try:\n",
    "                    st = client.get_waveforms(network=net, station=sta, location=loc, channel=chan, starttime=starttime-60*60*24*30*6, endtime=endtime-60*60*24*30*6)\n",
    "                except Exception as e2:\n",
    "                    print(f\"Error downloading data for alternative dates for station {sta}: {e2}\")\n",
    "                    continue\n",
    "\n",
    "            # Check for gaps and re-download if necessary\n",
    "            if len(st.get_gaps()) > 0:\n",
    "                print(f\"Gaps exist in waveforms for station {sta}... trying alternative dates again\")\n",
    "                try:\n",
    "                    st = client.get_waveforms(network=net, station=sta, location=loc, channel=chan, starttime=starttime-60*60*24*30*6, endtime=endtime-60*60*24*30*6)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error re-downloading data for station {sta}: {e}\")\n",
    "                    continue\n",
    "\n",
    "                if len(st.get_gaps()) > 0:\n",
    "                    print(f\"Still gaps exist for station {sta}, skipping\")\n",
    "                    continue\n",
    "\n",
    "            # Write the waveforms to a file\n",
    "            st.write(output_file, format=\"MSEED\")\n",
    "            print(f\"Waveforms written to {output_file}\")\n",
    "\n",
    "print(\"Processing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5dc8ea-97f1-4074-a71e-09df6ee2c5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy.clients.fdsn import Client\n",
    "from obspy import UTCDateTime\n",
    "import os\n",
    "\n",
    "Ndays = 1  # Duration of each download period (1 day)\n",
    "total_days = 10  # Total number of successive days to download\n",
    "\n",
    "client = Client(\"IRIS\")\n",
    "net = \"Z9\"\n",
    "sta = \"**\"\n",
    "loc = \"**\"\n",
    "chan = \"BH?\"\n",
    "\n",
    "# Ensure the base output directory exists\n",
    "base_output_dir = \"outputloopdaysnew\"\n",
    "os.makedirs(base_output_dir, exist_ok=True)\n",
    "\n",
    "for network in clt:\n",
    "    for station in network:\n",
    "        # Get station and network codes\n",
    "        sta = station.code\n",
    "        net = network.code\n",
    "        \n",
    "        try:\n",
    "            # Initial start and end times\n",
    "            initial_starttime = UTCDateTime((station.creation_date + 365*24*60*60).strftime('%Y-%m-%d'))\n",
    "        except Exception as e:\n",
    "            print(f\"Error in date conversion for station {station.code}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        for day_offset in range(total_days):\n",
    "            # Calculate start and end time for the current day\n",
    "            starttime = initial_starttime + day_offset * 24 * 60 * 60\n",
    "            endtime = starttime + Ndays * 24 * 60 * 60\n",
    "\n",
    "            # Create a separate folder for each day within the station's directory\n",
    "            station_output_dir = os.path.join(base_output_dir, f\"{net}.{sta}\")\n",
    "            day_output_dir = os.path.join(station_output_dir, f\"day{day_offset + 1}\")\n",
    "            os.makedirs(day_output_dir, exist_ok=True)\n",
    "\n",
    "            output_file = os.path.join(day_output_dir, f\"{net}.{sta}.day{day_offset + 1}.mseed\")\n",
    "\n",
    "            # Skip download if file already exists\n",
    "            if os.path.exists(output_file):\n",
    "                print(f\"File {output_file} already exists, skipping download.\")\n",
    "                continue\n",
    "\n",
    "            print(f\"Processing station: {sta}, Day: {day_offset + 1}\")\n",
    "\n",
    "            try:\n",
    "                st = client.get_waveforms(network=net, station=sta, location=loc, channel=chan, starttime=starttime, endtime=endtime)\n",
    "            except Exception as e:\n",
    "                print(f\"Error downloading data for station {sta}: {e}. Trying alternative dates...\")\n",
    "                try:\n",
    "                    st = client.get_waveforms(network=net, station=sta, location=loc, channel=chan, starttime=starttime-60*60*24*30*6, endtime=endtime-60*60*24*30*6)\n",
    "                except Exception as e2:\n",
    "                    print(f\"Error downloading data for alternative dates for station {sta}: {e2}\")\n",
    "                    continue\n",
    "\n",
    "            # Check for gaps and re-download if necessary\n",
    "            if len(st.get_gaps()) > 0:\n",
    "                print(f\"Gaps exist in waveforms for station {sta}... trying alternative dates again\")\n",
    "                try:\n",
    "                    st = client.get_waveforms(network=net, station=sta, location=loc, channel=chan, starttime=starttime-60*60*24*30*6, endtime=endtime-60*60*24*30*6)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error re-downloading data for station {sta}: {e}\")\n",
    "                    continue\n",
    "\n",
    "                if len(st.get_gaps()) > 0:\n",
    "                    print(f\"Still gaps exist for station {sta}, skipping\")\n",
    "                    continue\n",
    "\n",
    "            # Write the waveforms to a file\n",
    "            st.write(output_file, format=\"MSEED\")\n",
    "            print(f\"Waveforms written to {output_file}\")\n",
    "\n",
    "print(\"Processing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bc0c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ndays = 1\n",
    "\n",
    "\n",
    "client = Client(\"IRIS\")\n",
    "#t1 = (station.creation_date + 1*365*24*60*60).strftime('%Y-%m-%d')\n",
    "#t2 = (station.creation_date + 1*365*24*60*60 + Ndays*24*60*60).strftime('%Y-%m-%d')\n",
    "net = \"Z9\"\n",
    "sta = \"**\"\n",
    "loc = \"**\"\n",
    "chan = \"BH?\"\n",
    "#t1 = UTCDateTime (\"2012-10-01\")\n",
    "#t2 = UTCDateTime (\"2012-10-02\")\n",
    "\n",
    "#starttime  = UTCDateTime(\"2012-02-27T00:00:00.000\")\n",
    "#endtime = starttime +60 *60 *24\n",
    "\n",
    "   \n",
    "for network in clt:\n",
    "    for station in network:\n",
    "        # Compute HVSR for each station\n",
    "        \n",
    "        starttime =  UTCDateTime((station.creation_date + 1*365*24*60*60).strftime('%Y-%m-%d'))\n",
    "        endtime =  UTCDateTime((station.creation_date + 1*365*24*60*60 + Ndays*24*60*60).strftime('%Y-%m-%d'))\n",
    "        \n",
    "        sta = station.code\n",
    "        #loc = '--'\n",
    "        net = network.code\n",
    "        print (sta)\n",
    "\n",
    "        try:\n",
    "            st = client.get_waveforms(network= net , station= sta, location= loc, channel= chan, starttime= starttime, endtime= endtime) #attach_response=True)    \n",
    "        except:\n",
    "            print('Error downloading data... try subtracting 6 months from start/end time')\n",
    "            st = client.get_waveforms(network= net , station= sta, location= loc, channel= chan, starttime= starttime-60*60*24*30*6, endtime= endtime-60*60*24*30*6) #attach_response=True)\n",
    "        \n",
    "        # Merge waveforms if gaps exist\n",
    "        if len(st.get_gaps())>0:\n",
    "            print('Gaps exist in waveforms... try subtracting 6 months from start/end time')\n",
    "            # st.merge(method=0, fill_value=None)\n",
    "            st = client.get_waveforms(network= net , station= sta, location= loc, channel= chan, starttime= starttime-60*60*24*30*6, endtime= endtime-60*60*24*30*6) #attach_response=True)\n",
    "            \n",
    "            if len(st.get_gaps())>0:\n",
    "                continue\n",
    "\n",
    "        st.write (net+'.'+sta+'.'+starttime.strftime('%Y-%m-%d')+'.'+endtime.strftime('%Y-%m-%d')+\".mseed\", format =\"MSEED\")\n",
    "            \n",
    "print (st)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e11f26f-498c-4b09-aec7-2d6b20398460",
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy.clients.fdsn import Client\n",
    "from obspy import UTCDateTime\n",
    "import os\n",
    "\n",
    "Ndays = 1\n",
    "\n",
    "client = Client(\"IRIS\")\n",
    "net = \"Z9\"\n",
    "sta = \"**\"\n",
    "loc = \"**\"\n",
    "chan = \"BH?\"\n",
    "\n",
    "# Ensure the output directory exists\n",
    "output_dir = \"output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for network in clt:\n",
    "    for station in network:\n",
    "        # Compute HVSR for each station\n",
    "        \n",
    "        try:\n",
    "            # Convert creation_date to datetime, add one year and then the number of days\n",
    "            starttime = UTCDateTime((station.creation_date + 365*24*60*60).strftime('%Y-%m-%d'))\n",
    "            endtime = UTCDateTime((station.creation_date + 365*24*60*60 + Ndays*24*60*60).strftime('%Y-%m-%d'))\n",
    "        except Exception as e:\n",
    "            print(f\"Error in date conversion for station {station.code}: {e}\")\n",
    "            continue\n",
    "\n",
    "        sta = station.code\n",
    "        net = network.code\n",
    "        output_file = os.path.join(output_dir, f\"{net}.{sta}.{starttime.strftime('%Y-%m-%d')}.{endtime.strftime('%Y-%m-%d')}.mseed\")\n",
    "\n",
    "        # Skip download if file already exists\n",
    "        if os.path.exists(output_file):\n",
    "            print(f\"File {output_file} already exists, skipping download.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing station: {sta}\")\n",
    "\n",
    "        try:\n",
    "            st = client.get_waveforms(network=net, station=sta, location=loc, channel=chan, starttime=starttime, endtime=endtime)\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading data for station {sta}: {e}. Trying alternative dates...\")\n",
    "            try:\n",
    "                st = client.get_waveforms(network=net, station=sta, location=loc, channel=chan, starttime=starttime-60*60*24*30*6, endtime=endtime-60*60*24*30*6)\n",
    "            except Exception as e2:\n",
    "                print(f\"Error downloading data for alternative dates for station {sta}: {e2}\")\n",
    "                continue\n",
    "        \n",
    "        # Check for gaps and re-download if necessary\n",
    "        if len(st.get_gaps()) > 0:\n",
    "            print(f\"Gaps exist in waveforms for station {sta}... trying alternative dates again\")\n",
    "            try:\n",
    "                st = client.get_waveforms(network=net, station=sta, location=loc, channel=chan, starttime=starttime-60*60*24*30*6, endtime=endtime-60*60*24*30*6)\n",
    "            except Exception as e:\n",
    "                print(f\"Error re-downloading data for station {sta}: {e}\")\n",
    "                continue\n",
    "\n",
    "            if len(st.get_gaps()) > 0:\n",
    "                print(f\"Still gaps exist for station {sta}, skipping\")\n",
    "                continue\n",
    "\n",
    "        # Write the waveforms to a file\n",
    "        st.write(output_file, format=\"MSEED\")\n",
    "        print(f\"Waveforms written to {output_file}\")\n",
    "\n",
    "print(\"Processing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cf0de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "starttime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c87f20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input file name (may be a relative or full path).\n",
    "\n",
    "# file_name = \"UT.STN11.A2_C50.miniseed\"\n",
    "# file_name = \"UT.STN11.A2_C150.miniseed\"\n",
    "# file_name = \"UT.STN12.A2_C50.miniseed\"\n",
    "# file_name = \"UT.STN12.A2_C150.miniseed\"\n",
    "#file_name= \"april.mseed\"\n",
    "#file_path = \"/Users/birotimi/Desktop/PHD/HVSR-project/HVSR-master/hvsrpy/sesameapril/\"\n",
    "file_path = \"/Users/birotimi/Library/CloudStorage/OneDrive-SyracuseUniversity/Desktop/PHD/HVSR-project/HVSR-master/\"\n",
    "#file_name= \"/Users/birotimi/Desktop/PHD/HVSR-project/HVSR-master/hvsrpy/SESAMEAPRIL.mseed\"\n",
    "\n",
    "# Minimum frequency after resampling\n",
    "resample_fmin = 0.1  # Default value\n",
    "# Maximum frequency after resampling\n",
    "# resample_fmax = 50  # Default value\n",
    "# resample_fmax = sr/2\n",
    "\n",
    "# Window length in seconds. In general low frequency peaks require longer window lengths.\n",
    "# See the SESAME guidelines for specific window length recommendations.\n",
    "# windowlength = 60 # Default value\n",
    "    \n",
    "# windowlength = 250\n",
    "windowlength = 10 / resample_fmin\n",
    "\n",
    "# Boolean to control whether Butterworth filter is applied. \n",
    "# Geopsy does not apply a bandpass filter.\n",
    "\n",
    "filter_bool = False        \n",
    "\n",
    "# Low-cut frequency for bandpass filter.\n",
    "\n",
    "# filter_flow = 0.1 \n",
    "filter_flow = resample_fmin               \n",
    "\n",
    "# High-cut frequency for bandpass filter.\n",
    "filter_fhigh = 30                   \n",
    "# Filter order.\n",
    "filter_order = 5\n",
    "\n",
    "# Width of cosine taper {0. - 1.}. Geopsy default of 0.05 is equal to 0.1 -> 0.1 is recommended\n",
    "width = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d36a052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konno and Ohmachi smoothing constant. 40 is recommended.\n",
    "bandwidth = 40\n",
    "\n",
    "# Number of frequencies after resampling\n",
    "resample_fnum = 200\n",
    "# Type of resampling {'log', 'linear'}\n",
    "resample_type = 'log'\n",
    "\n",
    "# Upper and lower frequency limits to restrict peak selection. To use the entire range use `None`.\n",
    "peak_f_lower = None\n",
    "peak_f_upper = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590d0035",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Azimutal settings##\n",
    "\n",
    "# Rotation of horizontal components\n",
    "# azimuthal_inverval defines the spacing in degrees between considerd azimuths -> 15 is recommended.\n",
    "azimuthal_interval = 15\n",
    "azimuth = np.arange(0, 180, azimuthal_interval)\n",
    "\n",
    "# Boolean to control whether frequency-domain rejection-rejection algorithm is applied.\n",
    "# Geopsy does not offer this functionality.\n",
    "rejection_bool = True\n",
    "# Number of standard deviations to consider during rejection. Smaller values will reject more windows -> 2 is recommended.\n",
    "n = 2\n",
    "# Maximum number of iterations to perform for rejection -> 50 is recommended.\n",
    "max_iterations = 50\n",
    "\n",
    "# Distribution of f0 {\"lognormal\", \"normal\"}. Geopsy default \"normal\" -> \"lognormal\" is recommended.\n",
    "distribution_f0 = \"lognormal\"\n",
    "# Distribution of mean curve {\"lognormal\", \"normal\"}. Geopsy default \"lognormal\" -> \"lognormal\" is recommended.\n",
    "distribution_mc = \"lognormal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acce951",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Plot Settings##\n",
    "#Manually set the ylimits of the HVSR figures. Default is None so limits will be set automatically.\n",
    "ymin, ymax = 0, 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8630b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "file_path = \"/Users/birotimi/Library/CloudStorage/OneDrive-SyracuseUniversity/Desktop/PHD/HVSR-project/HVSR-master/\"\n",
    "file_name = file_path+\"Z9.D06.2013-05-04.2013-05-05.mseed\"\n",
    "\n",
    "pathlist = Path(file_path).glob('**/*.mseed')\n",
    "for path in pathlist:\n",
    "    print(path)\n",
    "\n",
    "    st = read(path)\n",
    "    sr  = st[0].stats.sampling_rate\n",
    "    print(sr)\n",
    "\n",
    "st_sta = read(file_name)\n",
    "\n",
    "#fig_out = './results/'+azimuth+'/figures/'\n",
    "#hvsrpy_out = './results/'+azimuth+'/hvsrpy/'\n",
    "#geopsy_out = './results/'+azimuth+'/geopsy/'\n",
    "\n",
    "#if not os.path.exists(fig_out):\n",
    " #      os.makedirs(fig_out)\n",
    "#if not os.path.exists(hvsrpy_out):\n",
    " #      os.makedirs(hvsrpy_out)\n",
    "#if not os.path.exists(geopsy_out):\n",
    " #      os.makedirs(geopsy_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b8090a",
   "metadata": {},
   "outputs": [],
   "source": [
    "st\n",
    "# sensor\n",
    "# sensor = hvsrpy.Sensor3c.from_mseed(file_name)\n",
    "# file_name\n",
    "hvsrpy.Sensor3c.from_mseed(\"/Users/birotimi/Library/CloudStorage/OneDrive-SyracuseUniversity/Desktop/PHD/HVSR-project/HVSR-master/Z9.D02.2012-05-17.2012-05-18.mseed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb5e7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Calculations##\n",
    "\n",
    "# Generate output directories\n",
    "method = 'multiple-azimuths'\n",
    "fig_out = './July/'+method+'/figures/'\n",
    "hvsrpy_out = './July/'+method+'/hvsrpy/'\n",
    "geopsy_out = './July/'+method+'/geopsy/'\n",
    "\n",
    "if not os.path.exists(fig_out):\n",
    "    os.makedirs(fig_out)\n",
    "if not os.path.exists(hvsrpy_out):\n",
    "    os.makedirs(hvsrpy_out)\n",
    "if not os.path.exists(geopsy_out):\n",
    "    os.makedirs(geopsy_out)\n",
    "\n",
    "# Loop over all mseed files in file_path\n",
    "\n",
    "pathlist = Path(file_path).glob('**/*.mseed')\n",
    "for path in pathlist:\n",
    "\n",
    "    file_name = path #file_path+\"Z9.D03.2013-05-04.2013-05-05.mseed\"\n",
    "    station_str = str(path).split('/')[-1].split('.mseed')[0]\n",
    "\n",
    "    print('Working on: '+station_str)\n",
    "\n",
    "    st = read (file_name)\n",
    "    sr  = st[0].stats.sampling_rate\n",
    "    start = time.time()\n",
    "    sensor = hvsrpy.Sensor3c.from_mseed(file_name)\n",
    "    resample_fmax = sr/2\n",
    "    bp_filter = {\"flag\":filter_bool, \"flow\":filter_flow, \"fhigh\":filter_fhigh, \"order\":filter_order}\n",
    "    resampling = {\"minf\":resample_fmin, \"maxf\":resample_fmax, \"nf\":resample_fnum, \"res_type\":resample_type}\n",
    "    hv = sensor.hv(windowlength, bp_filter, width, bandwidth, resampling, \"multiple-azimuths\", f_low=peak_f_lower, f_high=peak_f_upper, azimuth=azimuth)\n",
    "\n",
    "    # Check for bad data with a single value at all points\n",
    "    if np.sum(np.diff(st[0].data)) == 0:\n",
    "        print(\"Problem with \"+st[0].stats.channel+\" ... skipping\")\n",
    "        continue\n",
    "    elif np.sum(np.diff(st[1].data)) == 0:\n",
    "        print(\"Problem with \"+st[1].stats.channel+\" ... skipping\")\n",
    "        continue\n",
    "    elif np.sum(np.diff(st[2].data)) == 0:\n",
    "        print(\"Problem with \"+st[2].stats.channel+\" ... skipping\")\n",
    "        continue\n",
    "\n",
    "    if rejection_bool:\n",
    "        hv.reject_windows(n=n, max_iterations=max_iterations, distribution_f0=distribution_f0, distribution_mc=distribution_mc)\n",
    "\n",
    "    azimuths = [*hv.azimuths, 180.]\n",
    "    mesh_frq, mesh_azi = np.meshgrid(hv.frq, azimuths)\n",
    "    mesh_amp = hv.mean_curves(distribution=distribution_mc)\n",
    "    mesh_amp = np.vstack((mesh_amp, mesh_amp[0]))\n",
    "\n",
    "    end = time.time()\n",
    "    print(f\"Elapsed Time: {str(end-start)[0:4]} seconds\")\n",
    "\n",
    "    # Layout\n",
    "    fig = plt.figure(figsize=(6,5), dpi=150)\n",
    "    gs = fig.add_gridspec(nrows=2, ncols=2, wspace=0.3, hspace=0.1, width_ratios=(1.2,0.8))\n",
    "    ax0 = fig.add_subplot(gs[0:2, 0:1], projection='3d')\n",
    "    ax1 = fig.add_subplot(gs[0:1, 1:2])\n",
    "    ax2 = fig.add_subplot(gs[1:2, 1:2])\n",
    "    fig.subplots_adjust(bottom=0.21) \n",
    "\n",
    "    # Settings\n",
    "    individual_width = 0.3\n",
    "    median_width = 1.3\n",
    "\n",
    "    ## 3D Median Curve\n",
    "    ax = ax0\n",
    "    ax.plot_surface(np.log10(mesh_frq), mesh_azi, mesh_amp, rstride=1, cstride=1, cmap=cm.plasma, linewidth=0, antialiased=False)\n",
    "    for coord in list(\"xyz\"):\n",
    "        getattr(ax, f\"w_{coord}axis\").set_pane_color((1, 1,1))    \n",
    "    ax.set_xticks(np.log10(np.array([0.01, 0.1, 1, 10, 100])))\n",
    "    ax.set_xticklabels([\"$10^{\"+str(x)+\"}$\" for x in range(-2, 3)])\n",
    "    ax.set_xlim(np.log10((0.1, 30)))\n",
    "    ax.view_init(elev=30, azim=245)\n",
    "    ax.dist=12\n",
    "    ax.set_yticks(np.arange(0,180+45, 45))\n",
    "    ax.set_ylim(0,180)\n",
    "    ax.set_xlabel(\"Frequency (Hz)\")\n",
    "    ax.set_ylabel(\"Azimuth (deg)\")\n",
    "    ax.set_zlabel(\"HVSR Amplitude\")\n",
    "    pfrqs, pamps = hv.mean_curves_peak(distribution=distribution_mc)\n",
    "    pfrqs = np.array([*pfrqs, pfrqs[0]])\n",
    "    pamps = np.array([*pamps, pamps[0]])\n",
    "    ax.scatter(np.log10(pfrqs), azimuths, pamps*1.01, marker=\"s\", c=\"w\", edgecolors=\"k\", s=9)\n",
    "\n",
    "    ## 2D Median Curve\n",
    "    ax = ax1\n",
    "    contour = ax.contourf(mesh_frq, mesh_azi, mesh_amp, cmap=cm.plasma, levels=10)\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_ylabel(\"Azimuth (deg)\")\n",
    "    ax.set_yticks(np.arange(0,180+30, 30))\n",
    "    ax.set_ylim(0,180)\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"top\", size=\"5%\", pad=0.05)\n",
    "    fig.colorbar(contour, cax=cax, orientation=\"horizontal\")\n",
    "    cax.xaxis.set_ticks_position(\"top\")\n",
    "\n",
    "    ax.plot(pfrqs, azimuths, marker=\"s\", color=\"w\", linestyle=\"\", markersize=3, markeredgecolor=\"k\",\n",
    "            label=r\"$f_{0,mc,\\alpha}$\")\n",
    "\n",
    "    ## 2D Median Curve\n",
    "    ax = ax2\n",
    "\n",
    "    # Accepted Windows\n",
    "    label=\"Accepted\"\n",
    "    for amps in hv.amp:\n",
    "        for amp in amps:\n",
    "            ax.plot(hv.frq, amp, color=\"#888888\", linewidth=individual_width, zorder=2, label=label)\n",
    "            label=None\n",
    "\n",
    "    # Mean Curve\n",
    "    label = r\"$LM_{curve,AZ}$\" if distribution_mc==\"lognormal\" else r\"$Mean_{curve,AZ}$\"\n",
    "    ax.plot(hv.frq, hv.mean_curve(distribution_mc), color='k', label=label, linewidth=median_width, zorder=4)\n",
    "\n",
    "    # Mean +/- Curve\n",
    "    label = r\"$LM_{curve,AZ}$\"+\" ± 1 STD\" if distribution_mc==\"lognormal\" else r\"$Mean_{curve,AZ}$\"+\" ± 1 STD\"\n",
    "    ax.plot(hv.frq, hv.nstd_curve(-1, distribution=distribution_mc), color=\"k\", linestyle=\"--\",\n",
    "            linewidth=median_width, zorder=4, label=label)\n",
    "    ax.plot(hv.frq, hv.nstd_curve(+1, distribution=distribution_mc), color=\"k\", linestyle=\"--\",\n",
    "            linewidth=median_width, zorder=4)\n",
    "\n",
    "    # Window Peaks\n",
    "    label = r\"$f_{0,i,\\alpha}$\"\n",
    "    for frq, amp in zip(hv.peak_frq, hv.peak_amp):\n",
    "        ax.plot(frq, amp, linestyle=\"\", zorder=3, marker='o', markersize=2.5, markerfacecolor=\"#ffffff\",\n",
    "                markeredgewidth=0.5, markeredgecolor='k', label=label)\n",
    "        label=None\n",
    "\n",
    "    # Peak Mean Curve\n",
    "    ax.plot(hv.mc_peak_frq(distribution_mc), hv.mc_peak_amp(distribution_mc), linestyle=\"\", zorder=5,\n",
    "            marker='D', markersize=4, markerfacecolor='#66ff33', markeredgewidth=1, markeredgecolor='k', \n",
    "            label = r\"$f_{0,mc,AZ}$\")\n",
    "\n",
    "    # f0,az\n",
    "    if ymin is not None and ymax is not None:\n",
    "            ax.set_ylim((ymin, ymax))\n",
    "    label = r\"$LM_{f0,AZ}$\"+\" ± 1 STD\" if distribution_f0==\"lognormal\" else \"Mean \"+r\"$f_{0,AZ}$\"+\" ± 1 STD\"\n",
    "    _ymin, _ymax = ax.get_ylim()\n",
    "    ax.plot([hv.mean_f0_frq(distribution_f0)]*2, [ymin, ymax], linestyle=\"-.\", color=\"#000000\", zorder=6)\n",
    "    ax.fill([hv.nstd_f0_frq(-1, distribution_f0)]*2 + [hv.nstd_f0_frq(+1, distribution_f0)]*2, [_ymin, _ymax, _ymax, _ymin], \n",
    "            color = \"#ff8080\", label=label, zorder=1)\n",
    "    ax.set_ylim((_ymin, _ymax))\n",
    "\n",
    "    # Limits and labels\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_xlabel(\"Frequency (Hz)\")\n",
    "    ax.set_ylabel(\"HVSR Amplitude\")\n",
    "    for spine in [\"top\", \"right\"]:\n",
    "        ax.spines[spine].set_visible(False)\n",
    "        \n",
    "    # Lettering\n",
    "    xs, ys = [0.45, 0.85, 0.85], [0.81, 0.81, 0.47]  \n",
    "    for x, y, letter in zip(xs, ys, list(\"abc\")):\n",
    "        fig.text(x, y, f\"({letter})\", fontsize=12)\n",
    "        \n",
    "    # Legend\n",
    "    handles, labels = [], []\n",
    "    for ax in [ax2, ax1, ax0]:\n",
    "            _handles, _labels = ax.get_legend_handles_labels()\n",
    "            handles += _handles\n",
    "            labels += _labels\n",
    "    new_handles, new_labels = [], []\n",
    "    for index in [0, 5, 1, 2, 3, 4, 6]:\n",
    "        new_handles.append(handles[index])\n",
    "        new_labels.append(labels[index])\n",
    "    fig.legend(new_handles, new_labels, loc=\"lower center\", bbox_to_anchor=(0.47, 0), ncol=4,\n",
    "            columnspacing=0.5, handletextpad=0.4)\n",
    "    \n",
    "\n",
    "                # Print stats\n",
    "    print(\"\\nStatistics after rejection considering azimuth:\")\n",
    "    hv.print_stats(distribution_f0)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    ###################### Save figure ###################### \n",
    "\n",
    "    figure_name_out = fig_out+\"/\"+station_str+\"_hvsr_figure_az.png\"\n",
    "\n",
    "    fig.savefig(figure_name_out, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"Figure saved successfully!\")\n",
    "\n",
    "\n",
    "    ###################### Save results text file ###################### \n",
    "\n",
    "    file_name_out_hvsrpy = hvsrpy_out+\"/\"+station_str+\"_output_hvsrpy_az.hv\"\n",
    "\n",
    "    hv.to_file(file_name_out_hvsrpy, distribution_f0, distribution_mc, data_format=\"hvsrpy\")\n",
    "    print(\"Results saved successfully!\")\n",
    "\n",
    "\n",
    "    ###################### Save Geopsy text file ######################\n",
    "    \n",
    "   # file_name_out_geopsy = geopsy_out+\"/\"+station_str+\"_output_geopsy_az.hv\"\n",
    "\n",
    "   # hv.to_file(file_name_out_geopsy, distribution_f0, distribution_mc, data_format=\"geopsy\")\n",
    "    #print(\"Results saved successfully!\")\n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585aa2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634e56ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sensor = hvsrpy.Sensor3c.from_mseed(file_name)\n",
    "# st[2].plot()\n",
    "# st.print_gaps()\n",
    "# st.merge(method=0, fill_value=None).plot()\n",
    "# st = read (file_name)\n",
    "# st.merge(method=0, fill_value=None)\n",
    "# st\n",
    "# hvsrpy.Sensor3c.from_mseed(file_name)\n",
    "file_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c5c42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathlist = pathlist = Path(file_path).glob('**/*.mseed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d220aa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "##save fig to file##\n",
    "\n",
    "\n",
    "\n",
    "file_name_out = \"example_output_hvsrpy_az.hv\"\n",
    "\n",
    "hv.to_file(file_name_out, distribution_f0, distribution_mc)\n",
    "print(\"Results saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d589e1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b03f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open ('/Users/birotimi/Desktop/PHD/HVSR-project/HVSR-master/hvsrpy/results/multiple-azimuths/hvsrpy/.hv', 'r')\n",
    "Lines = file.readlines()\n",
    "    for line in Lines:\n",
    "    \n",
    "    \n",
    "#print (Lines[13].split(',')[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f340596",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathlist = sorted(Path(hvsrpy_out).glob('**/*.hv'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "f0_hvsr= np.array ([])\n",
    "peak_freq_hvsr =np.array([])\n",
    "peak_amplitude_hvsr = np.array([])\n",
    "lats=np.array([])\n",
    "lons=np.array([])\n",
    "for path in pathlist:\n",
    "    path_in_str = str(path)  \n",
    "   # print (path)\n",
    "    file = open (path, 'r')#('/Users/birotimi/Desktop/PHD/HVSR-project/HVSR-master/hvsrpy/results/multiple-azimuths/hvsrpy/.hv#file_path+\"Z9.D03.2013-05-04.2013-05-05.mseed\"\n",
    "    #f0 = str(path).split('/')[-1].split('.hv')[0]\n",
    "    Lines =file.readlines()\n",
    "\n",
    "    net = path_in_str.split('/')[-1].split('.')[0]\n",
    "    sta = path_in_str.split('/')[-1].split('.')[1]\n",
    "    #loc = path.split('/')[-1].split('.')[2]\n",
    "    starttime = path_in_str.split('/')[-1].split('.')[2]\n",
    "    endtime = path_in_str.split('/')[-1].split('.')[3].split('_output_hvsrpy_az')[0]\n",
    "\n",
    "     # Read station lat lon\n",
    "    inventory = client.get_stations(network=net, station=sta, starttime=starttime, endtime=endtime)\n",
    "    lat = inventory[0][0].latitude\n",
    "    lon = inventory[0][0].longitude\n",
    "    lats = np.append(lats, lat)\n",
    "    lons = np.append(lons, lon)\n",
    "    #print(lat)\n",
    "    \n",
    "    f0= float(Lines[13].split(',')[1])\n",
    "    f0_hvsr =np.append (f0_hvsr, f0)\n",
    "    #print(f0)\n",
    "    #print(len(f0_hvsr))\n",
    "    peak_freq = float(Lines[20].split (',')[1])\n",
    "    peak_freq_hvsr = np.append (peak_freq_hvsr, peak_freq )\n",
    "\n",
    "    peak_amplitude = float (Lines [21].split (',') [1])\n",
    "    peak_amplitude_hvsr = np.append (peak_amplitude_hvsr, peak_amplitude)\n",
    "\n",
    "    #print(peak_amplitude_hvsr)\n",
    "\n",
    "    #print (peak_freq)\n",
    "    #print (peak_freq_hvsr)\n",
    "\n",
    "    #stan_dev = float (Lines[15].split(',')[1])\n",
    "    #stan_dev_calculation = np.append (stan_dev_calculation, stan_dev)\n",
    "    #print (stan_dev_calculation)\n",
    "    \n",
    "    LM_dev = float (Lines [17].split ('.')[1])\n",
    "    LM_deviation = np.append (LM_deviation, LM_dev)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ab1f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "starttime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75cb74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path2grdfile = '//Users/birotimi/Desktop/PHD/HVSR-project/HVSR-master/hvsrpy/etopo1.grd'\n",
    "etopodata = Dataset(path2grdfile)\n",
    "lons_e = np.linspace(etopodata.variables['x_range'][0],\n",
    "                    etopodata.variables['x_range'][1],\n",
    "                    etopodata.variables['dimension'][0])\n",
    "lats_e = np.linspace(etopodata.variables['y_range'][0],\n",
    "                    etopodata.variables['y_range'][1],\n",
    "                    etopodata.variables['dimension'][1])\n",
    "etopo = etopodata.variables['z'][:]\n",
    "etopo = np.reshape(etopo,etopodata.variables['dimension'][::-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce551e63",
   "metadata": {},
   "outputs": [],
   "source": [
    " #PLOT PEAK FREQUENCY\n",
    "\n",
    "# Map projection\n",
    "data_projection = ccrs.PlateCarree()\n",
    "\n",
    "# Mask the bad stations\n",
    "#mask_bad_hvsr = (max_hvsr < 2) | (max_hvsr > 100) | (max_freq>18)\n",
    "mask_bad_hvsr = (f0_hvsr >990) \n",
    "\n",
    "# Generate the map\n",
    "ax = plt.axes(projection=data_projection)\n",
    "ax.set_extent([minlongitude-0.5, maxlongitude+0.5, minlatitude-0.5, maxlatitude+0.5], crs=data_projection)\n",
    "img_extent = (-180, 180, -90, 90)\n",
    "pos = ax.imshow(etopo, origin='upper', extent=img_extent, transform=data_projection,\n",
    "            cmap='gray', alpha=1, zorder=-1)\n",
    "cb = plt.colorbar(pos, ax=ax, shrink=0.8)\n",
    "cb.ax.set_title('Elev. (m)')\n",
    "cmax = etopo.max()\n",
    "cmin = etopo.min()\n",
    "pos.set_clim(-200,1000)\n",
    "ax.add_feature(cfeature.OCEAN,facecolor=cfeature.COLORS['water'])\n",
    "ax.add_feature(cfeature.LAKES.with_scale('10m'), facecolor=cfeature.COLORS['water'], zorder=0)\n",
    "# ax.add_feature(cfeature.RIVERS)\n",
    "ax.coastlines(zorder=0)\n",
    "\n",
    "# Plot bad stations first\n",
    "ax.scatter(lons[mask_bad_hvsr],lats[mask_bad_hvsr],marker='o',s=50,c='white',edgecolor='black', transform=data_projection)\n",
    "# Now plot good stations\n",
    "sc = ax.scatter(\n",
    "    lons[~mask_bad_hvsr],lats[~mask_bad_hvsr], marker='o', s=50, \n",
    "    # c=max_hvsr[~mask_bad_hvsr], \n",
    "    c=np.log10(f0_hvsr[~mask_bad_hvsr]),\n",
    "    cmap='Spectral',edgecolor='black', transform=data_projection)\n",
    "cb = plt.colorbar(sc)\n",
    "cb.set_label('Peak Frequency (Hz)')\n",
    "# ax.set_xlim(minlongitude,maxlongitude)\n",
    "# ax.set_ylim(minlatitude,maxlatitude)\n",
    "\n",
    "gl = ax.gridlines(crs= data_projection, draw_labels=True,\n",
    "                  linewidth=1, color='gray', alpha=0.5, linestyle='--', zorder=0)\n",
    "gl.xlabels_top = False\n",
    "gl.ylabels_right = False\n",
    "\n",
    "plt.savefig('hvsr_peak_frequency.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37f5be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot HVSR median curve peak amplitude and median frequency\n",
    "\n",
    "\n",
    "pathlist = sorted(Path(hvsrpy_out).glob('**/*.hv'))\n",
    "df= pathlist\n",
    "plt.figure ()\n",
    "peak_amplitudes = np.array ([])\n",
    "f_0 = np.array ([])\n",
    "ii = 0\n",
    "for path in pathlist:\n",
    "   peak_amplitudes =  np.append (peak_amplitudes, peak_amplitude)\n",
    "   f_0 =np.append (f_0, f0)\n",
    "   plt.plot (['f_0'], ['peak_amplitudes']) \n",
    "   plt.xlim(0,20)\n",
    "   plt.ylim(0,10)\n",
    "   plt.xlabel('LogNormal Frequency Hz')\n",
    "   plt.ylabel('Median Peak Amplitude')\n",
    "   #plt.xscale('log')\n",
    "   #plt.plot (f0,peak_amplitude,'ro')\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e53cbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "           \n",
    "\n",
    " #PLOT PEAK FREQUENCY\n",
    "\n",
    "# Map projection\n",
    "data_projection = ccrs.PlateCarree()\n",
    "\n",
    "# Mask the bad stations\n",
    "#mask_bad_hvsr = (max_hvsr < 2) | (max_hvsr > 100) | (max_freq>18)\n",
    "mask_bad_hvsr = (f0_hvsr >990) \n",
    "\n",
    "# Generate the map\n",
    "ax = plt.axes(projection=data_projection)\n",
    "ax.set_extent([minlongitude-0.5, maxlongitude+0.5, minlatitude-0.5, maxlatitude+0.5], crs=data_projection)\n",
    "img_extent = (-180, 180, -90, 90)\n",
    "pos = ax.imshow(etopo, origin='upper', extent=img_extent, transform=data_projection,\n",
    "            cmap='gray', alpha=1, zorder=-1)\n",
    "cb = plt.colorbar(pos, ax=ax, shrink=0.8)\n",
    "cb.ax.set_title('Elev. (m)')\n",
    "cmax = etopo.max()\n",
    "cmin = etopo.min()\n",
    "pos.set_clim(-200,1000)\n",
    "ax.add_feature(cfeature.OCEAN,facecolor=cfeature.COLORS['water'])\n",
    "ax.add_feature(cfeature.LAKES.with_scale('10m'), facecolor=cfeature.COLORS['water'], zorder=0)\n",
    "# ax.add_feature(cfeature.RIVERS)\n",
    "ax.coastlines(zorder=0)\n",
    "\n",
    "# Plot bad stations first\n",
    "ax.scatter(lons[mask_bad_hvsr],lats[mask_bad_hvsr],marker='o',s=50,c='white',edgecolor='black', transform=data_projection)\n",
    "# Now plot good stations\n",
    "sc = ax.scatter(\n",
    "    lons[~mask_bad_hvsr],lats[~mask_bad_hvsr], marker='o', s=50, \n",
    "    # c=max_hvsr[~mask_bad_hvsr], \n",
    "    c=np.log10(peak_freq_hvsr[~mask_bad_hvsr]),\n",
    "    cmap='Spectral',edgecolor='black', transform=data_projection)\n",
    "cb = plt.colorbar(sc)\n",
    "cb.set_label('Peak Frequency (Hz)')\n",
    "# ax.set_xlim(minlongitude,maxlongitude)\n",
    "# ax.set_ylim(minlatitude,maxlatitude)\n",
    "\n",
    "gl = ax.gridlines(crs= data_projection, draw_labels=True,\n",
    "                  linewidth=1, color='gray', alpha=0.5, linestyle='--', zorder=0)\n",
    "gl.xlabels_top = False\n",
    "gl.ylabels_right = False\n",
    "\n",
    "plt.savefig('hvsr_peak_frequency.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5456d461",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "mask_bad_hvsr = (np.abs(f0_hvsr-peak_freq_hvsr) > 2)\n",
    "plt.plot(f0_hvsr,peak_freq_hvsr,'o')\n",
    "plt.plot(f0_hvsr[mask_bad_hvsr],peak_freq_hvsr[mask_bad_hvsr],'or')\n",
    "plt.plot([0,25],[0,25],'--k')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654ddbb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc5de12",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathlist = sorted(Path(hvsrpy_out).glob('**/*.hv'))\n",
    "\n",
    "f0_hvsr= np.array ([])\n",
    "\n",
    "for path in pathlist:\n",
    "    print (path)\n",
    "    file = open (path, 'r')#('/Users/birotimi/Desktop/PHD/HVSR-project/HVSR-master/hvsrpy/results/multiple-azimuths/hvsrpy/.hv#file_path+\"Z9.D03.2013-05-04.2013-05-05.mseed\"\n",
    "    #f0 = str(path).split('/')[-1].split('.hv')[0]\n",
    "    Lines =file.readlines()\n",
    "\n",
    "    f0= float(Lines[13].split(',')[1])\n",
    "    f0_hvsr =np.append (f0_hvsr, f0)\n",
    "    #print(f0)\n",
    "    print(len(f0_hvsr))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8d7a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71227f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (peak_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a45817b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rec = 1/f0_hvsr\n",
    "df = pathlist # = sorted(Path(hvsrpy_out).glob('**/*.hv'))\n",
    "plt.figure ()\n",
    "\n",
    "plt.plot (df ['f0_hvsr'], df ['peak_freq_hvsr']) #label = table)\n",
    "          \n",
    "plt.ylim (0,20)\n",
    "plt.xlim (0,50)\n",
    "plt.xlabel ('f0_hvsr Hz')\n",
    "plt.ylabel ('peak_freq')\n",
    "plt.yscale ('log')\n",
    "\n",
    "plt.show"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hvsrpy-2.0",
   "language": "python",
   "name": "hvsrpy-2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
